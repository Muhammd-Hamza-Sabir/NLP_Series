{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "388a12ff",
   "metadata": {},
   "source": [
    "# Downloading Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "136956e1",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kaggle\n",
      "  Downloading kaggle-1.5.16.tar.gz (83 kB)\n",
      "                                              0.0/83.6 kB ? eta -:--:--\n",
      "     -------------------                      41.0/83.6 kB 1.9 MB/s eta 0:00:01\n",
      "     ---------------------------            61.4/83.6 kB 656.4 kB/s eta 0:00:01\n",
      "     -------------------------------------- 83.6/83.6 kB 780.3 kB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: six>=1.10 in c:\\users\\muhammadhamzasabir\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from kaggle) (1.16.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\muhammadhamzasabir\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from kaggle) (2023.7.22)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\muhammadhamzasabir\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from kaggle) (2.8.2)\n",
      "Requirement already satisfied: requests in c:\\users\\muhammadhamzasabir\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from kaggle) (2.31.0)\n",
      "Collecting tqdm (from kaggle)\n",
      "  Downloading tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "                                              0.0/78.3 kB ? eta -:--:--\n",
      "     ---------------                          30.7/78.3 kB 1.4 MB/s eta 0:00:01\n",
      "     -----------------------------          61.4/78.3 kB 825.8 kB/s eta 0:00:01\n",
      "     -------------------------------------- 78.3/78.3 kB 872.0 kB/s eta 0:00:00\n",
      "Collecting python-slugify (from kaggle)\n",
      "  Downloading python_slugify-8.0.1-py2.py3-none-any.whl (9.7 kB)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\muhammadhamzasabir\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from kaggle) (2.0.4)\n",
      "Collecting bleach (from kaggle)\n",
      "  Downloading bleach-6.0.0-py3-none-any.whl (162 kB)\n",
      "                                              0.0/162.5 kB ? eta -:--:--\n",
      "     -------                                  30.7/162.5 kB ? eta -:--:--\n",
      "     --------------                          61.4/162.5 kB 1.1 MB/s eta 0:00:01\n",
      "     ------------------------             112.6/162.5 kB 939.4 kB/s eta 0:00:01\n",
      "     ------------------------             112.6/162.5 kB 939.4 kB/s eta 0:00:01\n",
      "     -------------------------------      143.4/162.5 kB 655.8 kB/s eta 0:00:01\n",
      "     -------------------------------      143.4/162.5 kB 655.8 kB/s eta 0:00:01\n",
      "     ------------------------------------ 162.5/162.5 kB 574.5 kB/s eta 0:00:00\n",
      "Collecting webencodings (from bleach->kaggle)\n",
      "  Downloading webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Collecting text-unidecode>=1.3 (from python-slugify->kaggle)\n",
      "  Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "                                              0.0/78.2 kB ? eta -:--:--\n",
      "     ---------------                          30.7/78.2 kB 1.3 MB/s eta 0:00:01\n",
      "     -----------------------------          61.4/78.2 kB 812.7 kB/s eta 0:00:01\n",
      "     -------------------------------------- 78.2/78.2 kB 722.5 kB/s eta 0:00:00\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\muhammadhamzasabir\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->kaggle) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\muhammadhamzasabir\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->kaggle) (3.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\muhammadhamzasabir\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm->kaggle) (0.4.6)\n",
      "Building wheels for collected packages: kaggle\n",
      "  Building wheel for kaggle (pyproject.toml): started\n",
      "  Building wheel for kaggle (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for kaggle: filename=kaggle-1.5.16-py3-none-any.whl size=110693 sha256=8c959125265d2d615e05ef25f2f2ccd342fe0021204e0a94caa0715da3828ba1\n",
      "  Stored in directory: c:\\users\\muhammadhamzasabir\\appdata\\local\\pip\\cache\\wheels\\6a\\2b\\d0\\457dd27de499e9423caf738e743c4a3f82886ee6b19f89d5b7\n",
      "Successfully built kaggle\n",
      "Installing collected packages: webencodings, text-unidecode, tqdm, python-slugify, bleach, kaggle\n",
      "Successfully installed bleach-6.0.0 kaggle-1.5.16 python-slugify-8.0.1 text-unidecode-1.3 tqdm-4.66.1 webencodings-0.5.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e0efaba",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\muhammadhamzasabir\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (23.1.2)\n",
      "Collecting pip\n",
      "  Downloading pip-23.2.1-py3-none-any.whl (2.1 MB)\n",
      "                                              0.0/2.1 MB ? eta -:--:--\n",
      "                                              0.0/2.1 MB ? eta -:--:--\n",
      "     -                                        0.1/2.1 MB 991.0 kB/s eta 0:00:03\n",
      "     -                                        0.1/2.1 MB 751.6 kB/s eta 0:00:03\n",
      "     --                                       0.1/2.1 MB 804.6 kB/s eta 0:00:03\n",
      "     --                                       0.1/2.1 MB 774.0 kB/s eta 0:00:03\n",
      "     --                                       0.1/2.1 MB 774.0 kB/s eta 0:00:03\n",
      "     --                                       0.1/2.1 MB 774.0 kB/s eta 0:00:03\n",
      "     --                                       0.2/2.1 MB 459.5 kB/s eta 0:00:05\n",
      "     -----                                    0.3/2.1 MB 770.1 kB/s eta 0:00:03\n",
      "     ------                                   0.3/2.1 MB 756.6 kB/s eta 0:00:03\n",
      "     ------                                   0.3/2.1 MB 776.5 kB/s eta 0:00:03\n",
      "     -------                                  0.4/2.1 MB 757.8 kB/s eta 0:00:03\n",
      "     -------                                  0.4/2.1 MB 755.6 kB/s eta 0:00:03\n",
      "     -------                                  0.4/2.1 MB 755.6 kB/s eta 0:00:03\n",
      "     -------                                  0.4/2.1 MB 755.6 kB/s eta 0:00:03\n",
      "     -------                                  0.4/2.1 MB 755.6 kB/s eta 0:00:03\n",
      "     --------                                 0.5/2.1 MB 626.3 kB/s eta 0:00:03\n",
      "     ---------                                0.5/2.1 MB 683.6 kB/s eta 0:00:03\n",
      "     -----------                              0.6/2.1 MB 747.3 kB/s eta 0:00:02\n",
      "     -----------                              0.6/2.1 MB 744.0 kB/s eta 0:00:02\n",
      "     ------------                             0.7/2.1 MB 737.3 kB/s eta 0:00:02\n",
      "     -------------                            0.7/2.1 MB 733.0 kB/s eta 0:00:02\n",
      "     -------------                            0.7/2.1 MB 733.0 kB/s eta 0:00:02\n",
      "     -------------                            0.7/2.1 MB 733.0 kB/s eta 0:00:02\n",
      "     -------------                            0.7/2.1 MB 733.0 kB/s eta 0:00:02\n",
      "     -------------                            0.7/2.1 MB 733.0 kB/s eta 0:00:02\n",
      "     -------------                            0.7/2.1 MB 619.0 kB/s eta 0:00:03\n",
      "     ---------------                          0.8/2.1 MB 699.0 kB/s eta 0:00:02\n",
      "     ----------------                         0.8/2.1 MB 707.4 kB/s eta 0:00:02\n",
      "     ----------------                         0.9/2.1 MB 705.3 kB/s eta 0:00:02\n",
      "     -----------------                        0.9/2.1 MB 702.7 kB/s eta 0:00:02\n",
      "     ------------------                       0.9/2.1 MB 710.2 kB/s eta 0:00:02\n",
      "     ------------------                       1.0/2.1 MB 708.6 kB/s eta 0:00:02\n",
      "     -------------------                      1.0/2.1 MB 699.2 kB/s eta 0:00:02\n",
      "     --------------------                     1.0/2.1 MB 711.8 kB/s eta 0:00:02\n",
      "     --------------------                     1.1/2.1 MB 696.3 kB/s eta 0:00:02\n",
      "     --------------------                     1.1/2.1 MB 709.7 kB/s eta 0:00:02\n",
      "     ---------------------                    1.1/2.1 MB 708.3 kB/s eta 0:00:02\n",
      "     ---------------------                    1.1/2.1 MB 686.9 kB/s eta 0:00:02\n",
      "     ---------------------                    1.1/2.1 MB 680.2 kB/s eta 0:00:02\n",
      "     ----------------------                   1.2/2.1 MB 679.5 kB/s eta 0:00:02\n",
      "     -----------------------                  1.2/2.1 MB 690.5 kB/s eta 0:00:02\n",
      "     -----------------------                  1.2/2.1 MB 696.2 kB/s eta 0:00:02\n",
      "     ------------------------                 1.3/2.1 MB 689.0 kB/s eta 0:00:02\n",
      "     ------------------------                 1.3/2.1 MB 694.0 kB/s eta 0:00:02\n",
      "     -------------------------                1.3/2.1 MB 699.0 kB/s eta 0:00:02\n",
      "     -------------------------                1.4/2.1 MB 697.9 kB/s eta 0:00:02\n",
      "     --------------------------               1.4/2.1 MB 696.8 kB/s eta 0:00:01\n",
      "     ---------------------------              1.4/2.1 MB 695.8 kB/s eta 0:00:01\n",
      "     ---------------------------              1.4/2.1 MB 690.3 kB/s eta 0:00:01\n",
      "     ---------------------------              1.5/2.1 MB 694.8 kB/s eta 0:00:01\n",
      "     ----------------------------             1.5/2.1 MB 698.6 kB/s eta 0:00:01\n",
      "     -----------------------------            1.5/2.1 MB 697.6 kB/s eta 0:00:01\n",
      "     ------------------------------           1.6/2.1 MB 691.8 kB/s eta 0:00:01\n",
      "     ------------------------------           1.6/2.1 MB 695.8 kB/s eta 0:00:01\n",
      "     -------------------------------          1.6/2.1 MB 695.4 kB/s eta 0:00:01\n",
      "     -------------------------------          1.6/2.1 MB 690.2 kB/s eta 0:00:01\n",
      "     --------------------------------         1.7/2.1 MB 689.1 kB/s eta 0:00:01\n",
      "     --------------------------------         1.7/2.1 MB 693.3 kB/s eta 0:00:01\n",
      "     --------------------------------         1.7/2.1 MB 684.0 kB/s eta 0:00:01\n",
      "     ---------------------------------        1.8/2.1 MB 687.5 kB/s eta 0:00:01\n",
      "     ----------------------------------       1.8/2.1 MB 690.8 kB/s eta 0:00:01\n",
      "     ----------------------------------       1.8/2.1 MB 682.7 kB/s eta 0:00:01\n",
      "     -----------------------------------      1.8/2.1 MB 690.4 kB/s eta 0:00:01\n",
      "     -----------------------------------      1.9/2.1 MB 685.7 kB/s eta 0:00:01\n",
      "     ------------------------------------     1.9/2.1 MB 685.1 kB/s eta 0:00:01\n",
      "     -------------------------------------    1.9/2.1 MB 691.9 kB/s eta 0:00:01\n",
      "     -------------------------------------    2.0/2.1 MB 695.2 kB/s eta 0:00:01\n",
      "     --------------------------------------   2.0/2.1 MB 691.0 kB/s eta 0:00:01\n",
      "     --------------------------------------   2.0/2.1 MB 690.4 kB/s eta 0:00:01\n",
      "     ---------------------------------------  2.1/2.1 MB 689.8 kB/s eta 0:00:01\n",
      "     ---------------------------------------- 2.1/2.1 MB 688.5 kB/s eta 0:00:00\n",
      "Installing collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 23.1.2\n",
      "    Uninstalling pip-23.1.2:\n",
      "      Successfully uninstalled pip-23.1.2\n",
      "Successfully installed pip-23.2.1\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f53dd484",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be1c6ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['KAGGLE_CONFIG_DIR'] = '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ecb62d1",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading train.csv.zip to data"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0.00/54.9M [00:00<?, ?B/s]\n",
      "  2%|1         | 1.00M/54.9M [00:01<01:44, 541kB/s]\n",
      "  4%|3         | 2.00M/54.9M [00:03<01:27, 634kB/s]\n",
      "  5%|5         | 3.00M/54.9M [00:04<01:20, 675kB/s]\n",
      "  7%|7         | 4.00M/54.9M [00:06<01:20, 665kB/s]\n",
      "  9%|9         | 5.00M/54.9M [00:08<01:24, 622kB/s]\n",
      " 11%|#         | 6.00M/54.9M [00:09<01:18, 655kB/s]\n",
      " 13%|#2        | 7.00M/54.9M [00:11<01:16, 655kB/s]\n",
      " 15%|#4        | 8.00M/54.9M [00:12<01:11, 689kB/s]\n",
      " 16%|#6        | 9.00M/54.9M [00:14<01:08, 701kB/s]\n",
      " 18%|#8        | 10.0M/54.9M [00:15<01:08, 688kB/s]\n",
      " 20%|##        | 11.0M/54.9M [00:17<01:10, 654kB/s]\n",
      " 22%|##1       | 12.0M/54.9M [00:19<01:12, 625kB/s]\n",
      " 24%|##3       | 13.0M/54.9M [00:21<01:15, 584kB/s]\n",
      " 25%|##5       | 14.0M/54.9M [00:22<01:10, 613kB/s]\n",
      " 27%|##7       | 15.0M/54.9M [00:25<01:13, 573kB/s]\n",
      " 29%|##9       | 16.0M/54.9M [00:27<01:14, 551kB/s]\n",
      " 31%|###       | 17.0M/54.9M [00:28<01:07, 593kB/s]\n",
      " 33%|###2      | 18.0M/54.9M [00:30<01:03, 610kB/s]\n",
      " 35%|###4      | 19.0M/54.9M [00:31<00:59, 635kB/s]\n",
      " 36%|###6      | 20.0M/54.9M [00:33<00:56, 647kB/s]\n",
      " 38%|###8      | 21.0M/54.9M [00:34<00:52, 672kB/s]\n",
      " 40%|####      | 22.0M/54.9M [00:36<00:50, 689kB/s]\n",
      " 42%|####1     | 23.0M/54.9M [00:37<00:49, 671kB/s]\n",
      " 44%|####3     | 24.0M/54.9M [00:39<00:47, 676kB/s]\n",
      " 46%|####5     | 25.0M/54.9M [00:40<00:45, 685kB/s]\n",
      " 47%|####7     | 26.0M/54.9M [00:42<00:45, 673kB/s]\n",
      " 49%|####9     | 27.0M/54.9M [00:43<00:43, 672kB/s]\n",
      " 51%|#####     | 28.0M/54.9M [00:45<00:42, 668kB/s]\n",
      " 53%|#####2    | 29.0M/54.9M [00:47<00:40, 673kB/s]\n",
      " 55%|#####4    | 30.0M/54.9M [00:49<00:45, 571kB/s]\n",
      " 56%|#####6    | 31.0M/54.9M [00:51<00:47, 533kB/s]\n",
      " 58%|#####8    | 32.0M/54.9M [00:53<00:42, 571kB/s]\n",
      " 60%|######    | 33.0M/54.9M [00:54<00:38, 598kB/s]\n",
      " 62%|######1   | 34.0M/54.9M [00:56<00:34, 643kB/s]\n",
      " 64%|######3   | 35.0M/54.9M [00:57<00:31, 658kB/s]\n",
      " 66%|######5   | 36.0M/54.9M [00:59<00:30, 659kB/s]\n",
      " 67%|######7   | 37.0M/54.9M [01:00<00:27, 678kB/s]\n",
      " 69%|######9   | 38.0M/54.9M [01:02<00:25, 693kB/s]\n",
      " 71%|#######   | 39.0M/54.9M [01:03<00:24, 679kB/s]\n",
      " 73%|#######2  | 40.0M/54.9M [01:05<00:22, 690kB/s]\n",
      " 75%|#######4  | 41.0M/54.9M [01:06<00:20, 702kB/s]\n",
      " 76%|#######6  | 42.0M/54.9M [01:08<00:19, 710kB/s]\n",
      " 78%|#######8  | 43.0M/54.9M [01:09<00:17, 697kB/s]\n",
      " 80%|########  | 44.0M/54.9M [01:11<00:16, 709kB/s]\n",
      " 82%|########1 | 45.0M/54.9M [01:12<00:14, 712kB/s]\n",
      " 84%|########3 | 46.0M/54.9M [01:14<00:13, 717kB/s]\n",
      " 86%|########5 | 47.0M/54.9M [01:16<00:13, 608kB/s]\n",
      " 87%|########7 | 48.0M/54.9M [01:18<00:11, 616kB/s]\n",
      " 89%|########9 | 49.0M/54.9M [01:19<00:10, 622kB/s]\n",
      " 91%|#########1| 50.0M/54.9M [01:21<00:07, 647kB/s]\n",
      " 93%|#########2| 51.0M/54.9M [01:22<00:06, 658kB/s]\n",
      " 95%|#########4| 52.0M/54.9M [01:24<00:04, 660kB/s]\n",
      " 96%|#########6| 53.0M/54.9M [01:26<00:03, 639kB/s]\n",
      " 98%|#########8| 54.0M/54.9M [01:28<00:01, 532kB/s]\n",
      "100%|##########| 54.9M/54.9M [01:30<00:00, 517kB/s]\n",
      "100%|##########| 54.9M/54.9M [01:30<00:00, 634kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions download -c quora-insincere-questions-classification -f train.csv -p data\n",
    "!kaggle competitions download -c quora-insincere-questions-classification -f test.csv -p data\n",
    "!kaggle competitions download -c quora-insincere-questions-classification -f sample_submission.csv -p data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde88ef5",
   "metadata": {},
   "source": [
    "# Exploring Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a805c7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "750bd0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fname = './data/train.csv.zip'\n",
    "test_fname = './data/test.csv.zip'\n",
    "sample_fname = './data/sample_submission.csv.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0c6ad76",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train_df = pd.read_csv(train_fname)\n",
    "raw_test_df = pd.read_csv(test_fname)\n",
    "sample_df = pd.read_csv(sample_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "412c8bce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00002165364db923c7e6</td>\n",
       "      <td>How did Quebec nationalists see their province...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000032939017120e6e44</td>\n",
       "      <td>Do you have an adopted dog, how would you enco...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000412ca6e4628ce2cf</td>\n",
       "      <td>Why does velocity affect time? Does velocity a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000042bf85aa498cd78e</td>\n",
       "      <td>How did Otto von Guericke used the Magdeburg h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000455dfa3e01eae3af</td>\n",
       "      <td>Can I convert montra helicon D to a mountain b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid                                      question_text  \\\n",
       "0  00002165364db923c7e6  How did Quebec nationalists see their province...   \n",
       "1  000032939017120e6e44  Do you have an adopted dog, how would you enco...   \n",
       "2  0000412ca6e4628ce2cf  Why does velocity affect time? Does velocity a...   \n",
       "3  000042bf85aa498cd78e  How did Otto von Guericke used the Magdeburg h...   \n",
       "4  0000455dfa3e01eae3af  Can I convert montra helicon D to a mountain b...   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e247d35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    0.93813\n",
       "1    0.06187\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train_df['target'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d65f6acc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='target'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_train_df['target'].value_counts(normalize=True).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7aa513d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sincere_df = raw_train_df[raw_train_df['target']==0].copy()\n",
    "insincere_df = raw_train_df[raw_train_df['target']==1].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67f02bbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['How did Quebec nationalists see their province as a nation in the 1960s?',\n",
       "       'Do you have an adopted dog, how would you encourage people to adopt and not shop?',\n",
       "       'Why does velocity affect time? Does velocity affect space geometry?',\n",
       "       'How did Otto von Guericke used the Magdeburg hemispheres?',\n",
       "       'Can I convert montra helicon D to a mountain bike by just changing the tyres?',\n",
       "       'Is Gaza slowly becoming Auschwitz, Dachau or Treblinka for Palestinians?',\n",
       "       'Why does Quora automatically ban conservative opinions when reported, but does not do the same for liberal views?',\n",
       "       'Is it crazy if I wash or wipe my groceries off? Germs are everywhere.',\n",
       "       'Is there such a thing as dressing moderately, and if so, how is that different than dressing modestly?',\n",
       "       'Is it just me or have you ever been in this phase wherein you became ignorant to the people you once loved, completely disregarding their feelings/lives so you get to have something go your way and feel temporarily at ease. How did things change?'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sincere_df['question_text'].values[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00b19d4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Has the United States become the largest dictatorship in the world?',\n",
       "       'Which babies are more sweeter to their parents? Dark skin babies or light skin babies?',\n",
       "       \"If blacks support school choice and mandatory sentencing for criminals why don't they vote Republican?\",\n",
       "       'I am gay boy and I love my cousin (boy). He is sexy, but I dont know what to do. He is hot, and I want to see his di**. What should I do?',\n",
       "       'Which races have the smallest penis?',\n",
       "       'Why do females find penises ugly?',\n",
       "       'How do I marry an American woman for a Green Card? How much do they charge?',\n",
       "       \"Why do Europeans say they're the superior race, when in fact it took them over 2,000 years until mid 19th century to surpass China's largest economy?\",\n",
       "       'Did Julius Caesar bring a tyrannosaurus rex on his campaigns to frighten the Celts into submission?',\n",
       "       \"In what manner has Republican backing of 'states rights' been hypocritical and what ways have they actually restricted the ability of states to make their own laws?\"],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insincere_df['question_text'].values[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c43ab45a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000163e3ea7c7a74cd7</td>\n",
       "      <td>Why do so many women become so rude and arroga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00002bd4fb5d505b9161</td>\n",
       "      <td>When should I apply for RV college of engineer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00007756b4a147d2b0b3</td>\n",
       "      <td>What is it really like to be a nurse practitio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000086e4b7e1c7146103</td>\n",
       "      <td>Who are entrepreneurs?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000c4c3fbe8785a3090</td>\n",
       "      <td>Is education really making good people nowadays?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375801</th>\n",
       "      <td>ffff7fa746bd6d6197a9</td>\n",
       "      <td>How many countries listed in gold import in in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375802</th>\n",
       "      <td>ffffa1be31c43046ab6b</td>\n",
       "      <td>Is there an alternative to dresses on formal p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375803</th>\n",
       "      <td>ffffae173b6ca6bfa563</td>\n",
       "      <td>Where I can find best friendship quotes in Tel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375804</th>\n",
       "      <td>ffffb1f7f1a008620287</td>\n",
       "      <td>What are the causes of refraction of light?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375805</th>\n",
       "      <td>fffff85473f4699474b0</td>\n",
       "      <td>Climate change is a worrying topic. How much t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>375806 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         qid  \\\n",
       "0       0000163e3ea7c7a74cd7   \n",
       "1       00002bd4fb5d505b9161   \n",
       "2       00007756b4a147d2b0b3   \n",
       "3       000086e4b7e1c7146103   \n",
       "4       0000c4c3fbe8785a3090   \n",
       "...                      ...   \n",
       "375801  ffff7fa746bd6d6197a9   \n",
       "375802  ffffa1be31c43046ab6b   \n",
       "375803  ffffae173b6ca6bfa563   \n",
       "375804  ffffb1f7f1a008620287   \n",
       "375805  fffff85473f4699474b0   \n",
       "\n",
       "                                            question_text  \n",
       "0       Why do so many women become so rude and arroga...  \n",
       "1       When should I apply for RV college of engineer...  \n",
       "2       What is it really like to be a nurse practitio...  \n",
       "3                                  Who are entrepreneurs?  \n",
       "4        Is education really making good people nowadays?  \n",
       "...                                                   ...  \n",
       "375801  How many countries listed in gold import in in...  \n",
       "375802  Is there an alternative to dresses on formal p...  \n",
       "375803  Where I can find best friendship quotes in Tel...  \n",
       "375804        What are the causes of refraction of light?  \n",
       "375805  Climate change is a worrying topic. How much t...  \n",
       "\n",
       "[375806 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10eeab93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000163e3ea7c7a74cd7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00002bd4fb5d505b9161</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00007756b4a147d2b0b3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000086e4b7e1c7146103</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000c4c3fbe8785a3090</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375801</th>\n",
       "      <td>ffff7fa746bd6d6197a9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375802</th>\n",
       "      <td>ffffa1be31c43046ab6b</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375803</th>\n",
       "      <td>ffffae173b6ca6bfa563</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375804</th>\n",
       "      <td>ffffb1f7f1a008620287</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375805</th>\n",
       "      <td>fffff85473f4699474b0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>375806 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         qid  prediction\n",
       "0       0000163e3ea7c7a74cd7           0\n",
       "1       00002bd4fb5d505b9161           0\n",
       "2       00007756b4a147d2b0b3           0\n",
       "3       000086e4b7e1c7146103           0\n",
       "4       0000c4c3fbe8785a3090           0\n",
       "...                      ...         ...\n",
       "375801  ffff7fa746bd6d6197a9           0\n",
       "375802  ffffa1be31c43046ab6b           0\n",
       "375803  ffffae173b6ca6bfa563           0\n",
       "375804  ffffb1f7f1a008620287           0\n",
       "375805  fffff85473f4699474b0           0\n",
       "\n",
       "[375806 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b117fc12",
   "metadata": {},
   "source": [
    "# Text Preprocessing Technique:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7244607b",
   "metadata": {},
   "source": [
    "### TF-IDF (Term Frequency-Inverse Document Frequency):\n",
    "<p>\n",
    "    \n",
    "TF-IDF is a feature extraction technique for textual data. It not only converts documents or text into vectors of numeric values by means of count but aims to capture the importance of words in a collection of documents, so that we can feed the meaningful representation of text into Machine Learning model. Machine Learning models cannot process text directly that's why we first need to convert to have fixed length input for modeling. Here's a step-by-step explanation:\n",
    "\n",
    "<ol>\n",
    "    <li><strong>Term Frequency (TF):</strong><br>\n",
    "        Term Frequency (TF) provides information about the local importance of a word within a single document by measuring how often a word appears in a specific document. It is calculated using the formula:\n",
    "    </li>\n",
    "    <br>\n",
    "    <p>TF(word, document) = (Number of times the word appears in the document) / (Total number of words in the document)</p>\n",
    "    <br>\n",
    "    <li><strong>Inverse Document Frequency (IDF):</strong><br>\n",
    "        Inverse Document Frequency (IDF) quantifies how unique or important a word is across the entire corpus of documents by emphasizing words that appear in fewer documents, giving higher weights to rare and distinctive words. It's calculated using the formula:\n",
    "    </li>\n",
    "    <br>\n",
    "    <p>IDF(word) = log((Total number of documents) / (Number of documents containing the word))</p>\n",
    "    <br>\n",
    "    <li><strong>TF-IDF Calculation:</strong><br>\n",
    "        The TF-IDF score for a word in a document is the product of its Term Frequency (TF) and Inverse Document Frequency (IDF). The resulting value reflects how important a word is in a particular document relative to its occurrence across the entire corpus.\n",
    "    </li>\n",
    "    <br>\n",
    "    <p>TF-IDF(word, document) = TF(word, document) * IDF(word)</p>\n",
    "</ol>\n",
    "<br>\n",
    "\n",
    "\n",
    "\n",
    "<strong>Comparison with Bag of Words (BoW):</strong>\n",
    "\n",
    "<ul>\n",
    "    <li>Handling of Word Importance: BoW only considers the presence or absence of words and their counts in documents.TF-IDF takes into account both the frequency of a word within a document (TF) and its rarity across the entire corpus (IDF), providing a more nuanced representation of word importance.\n",
    "    </li>\n",
    "    <br>\n",
    "    <li>Impact of Common Words: BoW representation can give high weights to common words (e.g., \"the,\" \"and\") that appear frequently across documents. TF-IDF reduces the weight of common words by factoring in their inverse document frequency.\n",
    "    </li>\n",
    "    <br>\n",
    "    <li>Handling of Rare Words: BoW doesn't distinguish rare words from common ones, treating all words equally. TF-IDF gives higher weights to rare words, as their IDF values are higher.\n",
    "    </li>\n",
    "    <br>\n",
    "    <li>Sparsity: BoW vectors represent documents as counts of individual words. Since most documents won't contain all the words in the vocabulary, BoW vectors are often sparse due to the many zero-count entries. TF-IDF vectors attempt to weigh words based on their importance in a document relative to the entire corpus. However, if a word is not present in a document (TF = 0), its TF-IDF score for that document will indeed be 0, regardless of its IDF. This can result in sparse TF-IDF vectors, similar to BoW vectors.\n",
    "    </li>\n",
    "    <br>\n",
    "    <li>Contextual Information: BoW completely discards word order and context, treating documents as bags of words. TF-IDF retains some context information by considering both the local (TF) and global (IDF) significance of words.\n",
    "</ul>\n",
    "    \n",
    "    \n",
    "In summary, while both BoW and TF-IDF are methods for converting text into numerical representations, TF-IDF provides a more refined approach by considering the importance of words in both local and global contexts. It addresses some of the limitations of BoW and offers more meaningful representations, especially when dealing with larger corpora and documents.\n",
    "\n",
    "\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192570af",
   "metadata": {},
   "source": [
    "### Configure Count Vectorizer Parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d452a0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f222bce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\MuhammadHamzaSabir\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]     ..\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# word tokenizer\n",
    "from nltk import word_tokenize\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7605fe42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\MuhammadHamzaSabir\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]     ..\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# getting list of english stopwords\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "en_stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e82eab3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating stemmer object\n",
    "from nltk.stem import SnowballStemmer\n",
    "stemmer = SnowballStemmer(language=\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7d66c3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7c02c0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_stem(text):\n",
    "    return [stemmer.stem(token) for token in word_tokenize(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "11efc681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating count vectorizer object with configuration to incorporate preprocessing techniques together\n",
    "vectorizer = TfidfVectorizer(lowercase=True,\n",
    "                             stop_words=en_stopwords, #removing stopwords\n",
    "                             tokenizer=tokenize_and_stem #tokenization and stemming at the same time\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2f0c1741",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MuhammadHamzaSabir\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "C:\\Users\\MuhammadHamzaSabir\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens [\"'d\", \"'s\", 'abov', 'ani', 'becaus', 'befor', 'could', 'doe', 'dure', 'might', 'must', \"n't\", 'need', 'onc', 'onli', 'ourselv', 'sha', 'themselv', 'veri', 'whi', 'wo', 'would', 'yourselv'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 13min\n",
      "Wall time: 13min 5s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer(stop_words=[&#x27;i&#x27;, &#x27;me&#x27;, &#x27;my&#x27;, &#x27;myself&#x27;, &#x27;we&#x27;, &#x27;our&#x27;, &#x27;ours&#x27;,\n",
       "                            &#x27;ourselves&#x27;, &#x27;you&#x27;, &quot;you&#x27;re&quot;, &quot;you&#x27;ve&quot;, &quot;you&#x27;ll&quot;,\n",
       "                            &quot;you&#x27;d&quot;, &#x27;your&#x27;, &#x27;yours&#x27;, &#x27;yourself&#x27;, &#x27;yourselves&#x27;,\n",
       "                            &#x27;he&#x27;, &#x27;him&#x27;, &#x27;his&#x27;, &#x27;himself&#x27;, &#x27;she&#x27;, &quot;she&#x27;s&quot;,\n",
       "                            &#x27;her&#x27;, &#x27;hers&#x27;, &#x27;herself&#x27;, &#x27;it&#x27;, &quot;it&#x27;s&quot;, &#x27;its&#x27;,\n",
       "                            &#x27;itself&#x27;, ...],\n",
       "                tokenizer=&lt;function tokenize_and_stem at 0x000002015280E0C0&gt;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(stop_words=[&#x27;i&#x27;, &#x27;me&#x27;, &#x27;my&#x27;, &#x27;myself&#x27;, &#x27;we&#x27;, &#x27;our&#x27;, &#x27;ours&#x27;,\n",
       "                            &#x27;ourselves&#x27;, &#x27;you&#x27;, &quot;you&#x27;re&quot;, &quot;you&#x27;ve&quot;, &quot;you&#x27;ll&quot;,\n",
       "                            &quot;you&#x27;d&quot;, &#x27;your&#x27;, &#x27;yours&#x27;, &#x27;yourself&#x27;, &#x27;yourselves&#x27;,\n",
       "                            &#x27;he&#x27;, &#x27;him&#x27;, &#x27;his&#x27;, &#x27;himself&#x27;, &#x27;she&#x27;, &quot;she&#x27;s&quot;,\n",
       "                            &#x27;her&#x27;, &#x27;hers&#x27;, &#x27;herself&#x27;, &#x27;it&#x27;, &quot;it&#x27;s&quot;, &#x27;its&#x27;,\n",
       "                            &#x27;itself&#x27;, ...],\n",
       "                tokenizer=&lt;function tokenize_and_stem at 0x000002015280E0C0&gt;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "TfidfVectorizer(stop_words=['i', 'me', 'my', 'myself', 'we', 'our', 'ours',\n",
       "                            'ourselves', 'you', \"you're\", \"you've\", \"you'll\",\n",
       "                            \"you'd\", 'your', 'yours', 'yourself', 'yourselves',\n",
       "                            'he', 'him', 'his', 'himself', 'she', \"she's\",\n",
       "                            'her', 'hers', 'herself', 'it', \"it's\", 'its',\n",
       "                            'itself', ...],\n",
       "                tokenizer=<function tokenize_and_stem at 0x000002015280E0C0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "vectorizer.fit(raw_train_df['question_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "97e3f590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "215118"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "07b448d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['\\x02tñ\\x7f¼é\\x1aaùõ\\x8d¶rwìiìñó', '\\x10i', '\\x10new', '\\x10œø',\n",
       "       '\\x17', '!', '#', '$', '%', '&', \"'\", \"''\", \"'+\", \"'-\", \"'\\\\\",\n",
       "       \"'d\", \"'m\", \"'n\", \"'s\", \"'t\", \"'~\", \"'—\", \"'…\", '(', ')', '*', '+',\n",
       "       '++', '++=', '++\\\\sqrt', '++a/a', '++compil', '++i', '++j', '++p',\n",
       "       '+-', '+-100', '+-60', '+-ln', '+.1mg', '+/-', '+/-1', '+/-15v',\n",
       "       '+/-2', '+/720', '+0', '+0.00206x', '+0.12929=0', '+0.50', '+0o',\n",
       "       '+1', '+1,2,3,4', '+1.00', '+1.0pccharg', '+1.25', '+1.25d',\n",
       "       '+1.5', '+1.50', '+1/', '+1/100', '+1/2', '+1/3+1/4+', '+1/6',\n",
       "       '+1/e^x-1', '+1/q+1/r=', '+1/x', '+10', '+100', '+1000', '+100k',\n",
       "       '+10=', '+10^', '+10k', '+11', '+11x-6=0', '+12', '+125mhz',\n",
       "       '+12°', '+13', '+13x^2', '+1400', '+14x3-2x2+7x-8', '+15', '+150',\n",
       "       '+160', '+16=0', '+175', '+18', '+1=0', '+1\\\\', '+1k', '+2',\n",
       "       '+2.0', '+2/3', '+20', '+2000', '+2002', '+21', '+212', '+23'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names_out()[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b3b1c8e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 12min 2s\n",
      "Wall time: 12min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_inputs = vectorizer.transform(raw_train_df['question_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "23bdbf86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1306122, 215118)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d60782cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1306122x215118 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 10389128 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b5ad4597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How did Quebec nationalists see their province as a nation in the 1960s?'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train_df['question_text'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "784aa3dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_inputs[0].toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fe85592a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2min 44s\n",
      "Wall time: 2min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_inputs = vectorizer.transform(raw_test_df['question_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19eeaaaf",
   "metadata": {},
   "source": [
    "# Model Training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0a47e726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into train_set & validation_set\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6f8c55f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs, valid_inputs, train_target, valid_target = train_test_split(model_inputs, raw_train_df['target'], test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "db2409de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((914285, 215118), (391837, 215118))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inputs.shape, valid_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "07577132",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((914285,), (391837,))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target.shape, valid_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "24e441e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    0.937715\n",
       "1    0.062285\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ba9549f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    0.939097\n",
       "1    0.060903\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_target.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb9da61",
   "metadata": {},
   "source": [
    "### Logistic Regression Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8515524b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "551ab5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_ITER = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f4a408c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_model = LogisticRegression(max_iter=MAX_ITER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "14babcf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 50.7 s\n",
      "Wall time: 49.1 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "log_reg_model.fit(train_inputs, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fcb6a86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_preds = log_reg_model.predict(valid_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ff1337f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ad81a3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_accuracy = accuracy_score(valid_target, valid_preds)\n",
    "valid_precision = precision_score(valid_target, valid_preds)\n",
    "valid_recall = recall_score(valid_target, valid_preds)\n",
    "valid_f1 = f1_score(valid_target, valid_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "db49cc5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9521714386339217,\n",
       " 0.6872852233676976,\n",
       " 0.39389875963794835,\n",
       " 0.5007858075171145)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_accuracy, valid_precision, valid_recall, valid_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dd5794eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "96eb3ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_preds = np.random.choice((0, 1), len(valid_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ef55a72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_accuracy = accuracy_score(valid_target, random_preds)\n",
    "random_f1 = f1_score(valid_target, random_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a7a94e50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5012084106401387, 0.10913947372019564)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_accuracy, random_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71ca7dc",
   "metadata": {},
   "source": [
    "# Conclusion:\n",
    "\n",
    "<p>The aim of this notebook is to walkthrough you the TF-IDF (text processing techniques) as comapre to the BoW which we covered in last notebook. I'll continue from here to upwards till advanced NLP techniques, models etc. Modleing part done here is basic one, just to show how can Machine Learning models be used to train on text data.\n",
    "</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
